# Reynolds Orchestration System - Prometheus Alerting Rules
# Comprehensive monitoring and alerting for the orchestration system

groups:
  - name: reynolds-orchestrator
    rules:
      # Reynolds Core Health Alerts
      - alert: ReynoldsOrchestratorDown
        expr: up{job="reynolds-orchestrator"} == 0
        for: 1m
        labels:
          severity: critical
          component: orchestrator
        annotations:
          summary: "Reynolds Orchestrator is down"
          description: "The Reynolds Orchestrator has been down for more than 1 minute. This affects all agent coordination."

      - alert: ReynoldsHighTaskFailureRate
        expr: (rate(orchestrator_tasks_failed_total[5m]) / rate(orchestrator_tasks_total[5m])) > 0.1
        for: 2m
        labels:
          severity: warning
          component: orchestrator
        annotations:
          summary: "High task failure rate detected"
          description: "Task failure rate is {{ $value | humanizePercentage }} over the last 5 minutes."

      - alert: ReynoldsLowParallelExecutionRatio
        expr: (rate(orchestrator_parallel_tasks_total[10m]) / (rate(orchestrator_parallel_tasks_total[10m]) + rate(orchestrator_sequential_tasks_total[10m]))) < 0.6
        for: 5m
        labels:
          severity: warning
          component: orchestrator
        annotations:
          summary: "Low parallel execution ratio"
          description: "Parallel execution ratio is {{ $value | humanizePercentage }}, below the 60% threshold. Maximum Effort™ may be compromised."

      - alert: ReynoldsHighTaskDuration
        expr: histogram_quantile(0.95, rate(orchestrator_task_duration_seconds_bucket[5m])) > 300
        for: 3m
        labels:
          severity: warning
          component: orchestrator
        annotations:
          summary: "High task duration detected"
          description: "95th percentile task duration is {{ $value }}s, exceeding 5 minutes."

  - name: reynolds-loop-prevention
    rules:
      # Loop Prevention System Alerts
      - alert: ReynoldsLoopPreventionDown
        expr: up{job="reynolds-loop-prevention"} == 0
        for: 1m
        labels:
          severity: critical
          component: loop-prevention
        annotations:
          summary: "Reynolds Loop Prevention System is down"
          description: "Loop prevention monitoring is offline. System is vulnerable to infinite loops."

      - alert: ReynoldsConfidenceThresholdViolation
        expr: reynolds_loop_prevention_average_confidence < 0.999
        for: 30s
        labels:
          severity: critical
          component: loop-prevention
        annotations:
          summary: "99.9% confidence threshold violated"
          description: "Average confidence is {{ $value | humanizePercentage }}, below the 99.9% requirement. Loop prevention may be compromised."

      - alert: ReynoldsMultipleCircuitBreakersOpen
        expr: sum(reynolds_loop_prevention_circuit_breaker_open) > 3
        for: 2m
        labels:
          severity: critical
          component: loop-prevention
        annotations:
          summary: "Multiple circuit breakers are open"
          description: "{{ $value }} circuit breakers are currently open, indicating systemic loop detection issues."

      - alert: ReynoldsRapidLoopDetection
        expr: rate(reynolds_loop_prevention_loop_detected_total[5m]) > 0.5
        for: 1m
        labels:
          severity: warning
          component: loop-prevention
        annotations:
          summary: "High rate of loop detection"
          description: "Detecting {{ $value }} loops per second over the last 5 minutes."

      - alert: ReynoldsEventChainDepthExceeded
        expr: max(reynolds_loop_prevention_chain_depth) > 8
        for: 1m
        labels:
          severity: warning
          component: loop-prevention
        annotations:
          summary: "Event chain depth approaching limit"
          description: "Maximum event chain depth is {{ $value }}, approaching the limit of 10."

      - alert: ReynoldsHighEventProcessingTime
        expr: histogram_quantile(0.95, rate(reynolds_event_processing_duration_seconds_bucket[5m])) > 0.1
        for: 2m
        labels:
          severity: warning
          component: loop-prevention
        annotations:
          summary: "High event processing time"
          description: "95th percentile event processing time is {{ $value }}s, indicating performance issues."

  - name: reynolds-issue-obsession
    rules:
      # Reynolds Issue Obsession™ Alerts
      - alert: ReynoldsMaximumEffortOverdrive
        expr: reynolds_issue_obsession_patterns_total{obsession_type="maximum_effort_overdrive"} > 0
        for: 30s
        labels:
          severity: warning
          component: reynolds-personality
        annotations:
          summary: "Reynolds Maximum Effort™ Overdrive detected"
          description: "Reynolds is showing signs of Maximum Effort™ overdrive. Intervention may be required."

      - alert: ReynoldsTaskRepetitionObsession
        expr: reynolds_issue_obsession_patterns_total{obsession_type="task_repetition_obsession"} > 0
        for: 1m
        labels:
          severity: warning
          component: reynolds-personality
        annotations:
          summary: "Reynolds task repetition obsession detected"
          description: "Reynolds is showing obsessive behavior with task repetition. Reality check recommended."

      - alert: ReynoldsSupernaturalPerfectionism
        expr: reynolds_issue_obsession_patterns_total{obsession_type="supernatural_perfectionism"} > 0
        for: 2m
        labels:
          severity: info
          component: reynolds-personality
        annotations:
          summary: "Reynolds supernatural perfectionism detected"
          description: "Reynolds is exhibiting perfectionist behavior that may be impacting efficiency."

      - alert: ReynoldsCriticalObsessionIntervention
        expr: reynolds_issue_obsession_active{severity="critical"} > 0
        for: 10s
        labels:
          severity: critical
          component: reynolds-personality
        annotations:
          summary: "CRITICAL: Reynolds intervention required"
          description: "Reynolds is exhibiting critical obsession patterns. Immediate supernatural reality check required."

      - alert: ReynoldsMultipleActiveObsessions
        expr: sum(reynolds_issue_obsession_active) > 2
        for: 5m
        labels:
          severity: warning
          component: reynolds-personality
        annotations:
          summary: "Multiple Reynolds obsessions active"
          description: "{{ $value }} Reynolds obsession patterns are currently active. Maximum Effort™ may be misdirected."

  - name: reynolds-pattern-detection
    rules:
      # Pattern Detection Alerts
      - alert: ReynoldsRapidFirePattern
        expr: rate(reynolds_rapid_fire_patterns_total[1m]) > 0.1
        for: 30s
        labels:
          severity: warning
          component: pattern-detection
        annotations:
          summary: "Rapid fire execution pattern detected"
          description: "Detecting rapid fire patterns at {{ $value }} per second. System may be in a tight loop."

      - alert: ReynoldsRecursivePattern
        expr: rate(reynolds_recursive_patterns_total[5m]) > 0.05
        for: 1m
        labels:
          severity: warning
          component: pattern-detection
        annotations:
          summary: "Recursive execution pattern detected"
          description: "Detecting recursive patterns at {{ $value }} per second over 5 minutes."

      - alert: ReynoldsFanOutPattern
        expr: rate(reynolds_fan_out_patterns_total[5m]) > 0.02
        for: 2m
        labels:
          severity: warning
          component: pattern-detection
        annotations:
          summary: "Fan-out execution pattern detected"
          description: "Detecting fan-out patterns at {{ $value }} per second. Resource consumption may be excessive."

      - alert: ReynoldsExecutionTimeoutPrevention
        expr: rate(reynolds_loop_prevention_executions_prevented_total{pattern_type="execution_timeout"}[5m]) > 0.01
        for: 1m
        labels:
          severity: warning
          component: pattern-detection
        annotations:
          summary: "Execution timeouts being prevented"
          description: "Preventing execution timeouts at {{ $value }} per second. Tasks may be too complex or system overloaded."

  - name: reynolds-agents
    rules:
      # Agent Health Alerts
      - alert: AgentDown
        expr: up{job=~".*-agents"} == 0
        for: 2m
        labels:
          severity: warning
          component: agent
        annotations:
          summary: "Agent {{ $labels.instance }} is down"
          description: "Agent {{ $labels.instance }} of type {{ $labels.agent_type }} has been down for more than 2 minutes."

      - alert: LowAgentCount
        expr: sum(up{job=~".*-agents"}) < 3
        for: 1m
        labels:
          severity: critical
          component: agents
        annotations:
          summary: "Low agent count"
          description: "Only {{ $value }} agents are currently running. Minimum recommended is 3."

      - alert: AgentHighMemoryUsage
        expr: (container_memory_usage_bytes{name=~".*agent.*"} / container_spec_memory_limit_bytes{name=~".*agent.*"}) > 0.9
        for: 5m
        labels:
          severity: warning
          component: agent
        annotations:
          summary: "Agent {{ $labels.name }} high memory usage"
          description: "Agent {{ $labels.name }} memory usage is {{ $value | humanizePercentage }} of limit."

      - alert: AgentHighCPUUsage
        expr: rate(container_cpu_usage_seconds_total{name=~".*agent.*"}[5m]) > 0.8
        for: 5m
        labels:
          severity: warning
          component: agent
        annotations:
          summary: "Agent {{ $labels.name }} high CPU usage"
          description: "Agent {{ $labels.name }} CPU usage is {{ $value | humanizePercentage }}."

  - name: infrastructure
    rules:
      # Infrastructure Alerts
      - alert: RedisDown
        expr: up{job="redis"} == 0
        for: 1m
        labels:
          severity: critical
          component: infrastructure
        annotations:
          summary: "Redis is down"
          description: "Redis has been down for more than 1 minute. This affects agent coordination and caching."

      - alert: PostgreSQLDown
        expr: up{job="postgresql"} == 0
        for: 1m
        labels:
          severity: critical
          component: infrastructure
        annotations:
          summary: "PostgreSQL is down"
          description: "PostgreSQL has been down for more than 1 minute. This affects data persistence and agent learning."

      - alert: HighDiskUsage
        expr: (node_filesystem_avail_bytes{mountpoint="/"} / node_filesystem_size_bytes{mountpoint="/"}) < 0.1
        for: 5m
        labels:
          severity: critical
          component: infrastructure
        annotations:
          summary: "High disk usage"
          description: "Disk usage is above 90%. Available space: {{ $value | humanizeBytes }}."

      - alert: HighMemoryUsage
        expr: (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes) < 0.1
        for: 5m
        labels:
          severity: warning
          component: infrastructure
        annotations:
          summary: "High memory usage"
          description: "Memory usage is above 90%. Available memory: {{ $value | humanizeBytes }}."

  - name: monitoring
    rules:
      # Monitoring System Alerts
      - alert: PrometheusDown
        expr: up{job="prometheus"} == 0
        for: 2m
        labels:
          severity: warning
          component: monitoring
        annotations:
          summary: "Prometheus is down"
          description: "Prometheus has been down for more than 2 minutes. Monitoring may be impacted."

      - alert: GrafanaDown
        expr: up{job="grafana"} == 0
        for: 2m
        labels:
          severity: warning
          component: monitoring
        annotations:
          summary: "Grafana is down"
          description: "Grafana has been down for more than 2 minutes. Dashboards are not accessible."

      - alert: HighScrapeErrors
        expr: rate(prometheus_tsdb_symbol_table_size_bytes[5m]) > 0.1
        for: 5m
        labels:
          severity: warning
          component: monitoring
        annotations:
          summary: "High Prometheus scrape error rate"
          description: "Prometheus scrape error rate is {{ $value | humanizePercentage }}."

  - name: performance
    rules:
      # Performance Alerts
      - alert: HighResponseTime
        expr: histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m])) > 5
        for: 3m
        labels:
          severity: warning
          component: performance
        annotations:
          summary: "High response time"
          description: "95th percentile response time is {{ $value }}s."

      - alert: HighErrorRate
        expr: rate(http_requests_total{status=~"5.."}[5m]) / rate(http_requests_total[5m]) > 0.05
        for: 2m
        labels:
          severity: warning
          component: performance
        annotations:
          summary: "High error rate"
          description: "Error rate is {{ $value | humanizePercentage }}."

      - alert: LowThroughput
        expr: rate(orchestrator_tasks_completed_total[5m]) < 0.1
        for: 5m
        labels:
          severity: warning
          component: performance
        annotations:
          summary: "Low task throughput"
          description: "Task completion rate is {{ $value }} tasks/second."